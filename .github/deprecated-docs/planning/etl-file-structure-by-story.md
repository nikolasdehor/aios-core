# ETL Expansion Pack - Complete File Structure by Story

**Epic:** ETL Expansion Pack - Universal Data Collection
**Total Files:** 64+ files
**Total Effort:** 40 hours
**Organization:** By development story (P0 â†’ P1 â†’ P2)

---

## Story Organization

```
Story 1 (P0): Foundation - Week 1          15 files, 11 hours
Story 2 (P1): Collectors - Week 2          10 files, 6 hours
Story 3 (P1): MCP + Presets - Week 2       4 files, 4 hours
Story 4 (P1): Tests + Docs + CI - Week 2   25+ files, 12 hours
Story 5 (P2): Batch + Cache - Week 3       10 files, 7 hours
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:                                      64+ files, 40 hours
```

---

## Story 1: P0 Foundation (Week 1 - 11h)

**Goal:** Video transcription working via 1MCP
**Success:** MMOS can transcribe 1 video, cost tracking accurate

### Base Configuration Files (NEW)

```
expansion-packs/etl/
â”œâ”€â”€ package.json                                    # NEW
â”‚   {
â”‚     "name": "@aios/etl-toolkit",
â”‚     "version": "1.0.0",
â”‚     "description": "ETL Expansion Pack for AIOS",
â”‚     "main": "lib/mcp_server.js",
â”‚     "type": "module",
â”‚     "scripts": {
â”‚       "start": "node lib/mcp_server.js",
â”‚       "test": "jest",
â”‚       "lint": "eslint lib/"
â”‚     },
â”‚     "dependencies": {
â”‚       "@modelcontextprotocol/sdk": "^1.0.0"
â”‚     },
â”‚     "devDependencies": {
â”‚       "eslint": "^8.0.0",
â”‚       "jest": "^29.0.0"
â”‚     },
â”‚     "engines": {
â”‚       "node": ">=18.0.0"
â”‚     }
â”‚   }
â”‚
â”œâ”€â”€ requirements.txt                                # NEW
â”‚   # Core dependencies
â”‚   assemblyai==0.25.0
â”‚   beautifulsoup4==4.12.2
â”‚   requests==2.31.0
â”‚   pyyaml==6.0.1
â”‚   python-dotenv==1.0.0
â”‚   lxml==4.9.3
â”‚   html2text==2020.1.16
â”‚
â”‚   # Testing
â”‚   pytest==7.4.3
â”‚   pytest-cov==4.1.0
â”‚   pytest-asyncio==0.21.1
â”‚
â”‚   # Email processing (P1)
â”‚   # pypdf2, ebooklib (P1)
â”‚   # tiktoken (P1)
â”‚
â”œâ”€â”€ .gitignore                                      # NEW
â”‚   # Node
â”‚   node_modules/
â”‚   package-lock.json
â”‚
â”‚   # Python
â”‚   venv/
â”‚   __pycache__/
â”‚   *.pyc
â”‚   *.pyo
â”‚   *.egg-info/
â”‚   .pytest_cache/
â”‚   .coverage
â”‚   htmlcov/
â”‚
â”‚   # Environment
â”‚   .env
â”‚   .env.local
â”‚
â”‚   # IDE
â”‚   .vscode/
â”‚   .idea/
â”‚   *.swp
â”‚
â”‚   # Cache
â”‚   .cache/
â”‚
â”‚   # Logs
â”‚   *.log
â”‚   logs/
â”‚
â”œâ”€â”€ .env.example                                    # NEW
â”‚   # AssemblyAI API Key (required for video transcription)
â”‚   ASSEMBLYAI_API_KEY=your-assemblyai-api-key-here
â”‚
â”‚   # ETL Configuration (optional)
â”‚   ETL_CACHE_DIR=.cache/etl
â”‚   ETL_LOG_LEVEL=INFO
â”‚   ETL_MAX_RETRIES=3
â”‚
â”‚   # Rate Limiting (optional)
â”‚   ETL_WEB_RATE_LIMIT=60  # requests per minute
â”‚   ETL_VIDEO_CONCURRENT=10  # concurrent transcriptions
â”‚
â””â”€â”€ README.md                                       # NEW
    # ETL Expansion Pack

    Universal data collection toolkit for AIOS agents and MMOS.

    ## Quick Start

    ```bash
    # Install dependencies
    npm install
    pip install -r requirements.txt

    # Setup API keys
    cp .env.example .env
    # Edit .env and add your ASSEMBLYAI_API_KEY

    # Register in 1MCP
    1mcp mcp add etl-toolkit -- node $(pwd)/lib/mcp_server.js

    # Verify registration
    1mcp mcp list | grep etl-toolkit
    ```

    ## Features (P0 Complete)

    - âœ… **Video Transcription** (AssemblyAI, $0.67/hour, 95% accuracy)
    - ğŸš§ Web Scraping (Coming in P1)
    - ğŸš§ Email Sampling (Coming in P1)
    - ğŸš§ Book Processing (Coming in P1)

    ## Documentation

    - [API Reference](docs/API.md)
    - [Quick Start Guide](docs/QUICKSTART.md)
    - [Architecture](docs/ARCHITECTURE.md)
    - [Troubleshooting](docs/TROUBLESHOOTING.md)

    ## License

    MIT
```

### Core MCP Server (Node.js)

```
expansion-packs/etl/lib/
â”œâ”€â”€ mcp_server.js                                   # NEW (150 lines)
â”‚   #!/usr/bin/env node
â”‚   /**
â”‚    * ETL Toolkit MCP Server
â”‚    *
â”‚    * 1MCP-compatible server exposing ETL capabilities.
â”‚    * Bridges Node.js (MCP protocol) with Python (ETL logic).
â”‚    */
â”‚
â”‚   import { Server } from '@modelcontextprotocol/sdk/server/index.js';
â”‚   import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
â”‚   import { CallToolRequestSchema, ListToolsRequestSchema } from '@modelcontextprotocol/sdk/types.js';
â”‚   import { spawn } from 'child_process';
â”‚
â”‚   // Bridge to Python ETL
â”‚   async function callPythonETL(operation, params) {
â”‚     return new Promise((resolve, reject) => {
â”‚       const python = spawn('python', [
â”‚         'lib/bridge.py',
â”‚         operation,
â”‚         JSON.stringify(params)
â”‚       ], {
â”‚         cwd: process.env.ETL_ROOT || 'expansion-packs/etl'
â”‚       });
â”‚
â”‚       let stdout = '';
â”‚       let stderr = '';
â”‚
â”‚       python.stdout.on('data', (data) => stdout += data.toString());
â”‚       python.stderr.on('data', (data) => stderr += data.toString());
â”‚
â”‚       python.on('close', (code) => {
â”‚         if (code === 0) {
â”‚           try {
â”‚             resolve(JSON.parse(stdout));
â”‚           } catch (e) {
â”‚             reject(new Error(`Failed to parse: ${e.message}`));
â”‚           }
â”‚         } else {
â”‚           reject(new Error(`Python failed: ${stderr}`));
â”‚         }
â”‚       });
â”‚     });
â”‚   }
â”‚
â”‚   // Initialize MCP Server
â”‚   const server = new Server({
â”‚     name: 'etl-toolkit',
â”‚     version: '1.0.0',
â”‚   }, {
â”‚     capabilities: { tools: {} },
â”‚   });
â”‚
â”‚   // P0: Register 1 tool (transcribe_video)
â”‚   // P1: Will add 3 more tools
â”‚   server.setRequestHandler(ListToolsRequestSchema, async () => {
â”‚     return {
â”‚       tools: [
â”‚         {
â”‚           name: 'transcribe_video',
â”‚           description: 'Transcribe video/audio to text with timestamps',
â”‚           inputSchema: {
â”‚             type: 'object',
â”‚             properties: {
â”‚               source_url: {
â”‚                 type: 'string',
â”‚                 description: 'Video/audio URL'
â”‚               },
â”‚               language: {
â”‚                 type: 'string',
â”‚                 description: 'Language code (default: en)'
â”‚               },
â”‚               speaker_labels: {
â”‚                 type: 'boolean',
â”‚                 description: 'Enable speaker labels (default: true)'
â”‚               },
â”‚             },
â”‚             required: ['source_url'],
â”‚           },
â”‚         },
â”‚       ],
â”‚     };
â”‚   });
â”‚
â”‚   // Tool execution
â”‚   server.setRequestHandler(CallToolRequestSchema, async (request) => {
â”‚     const { name, arguments: args } = request.params;
â”‚
â”‚     try {
â”‚       const result = await callPythonETL(name, args);
â”‚       return {
â”‚         content: [{
â”‚           type: 'text',
â”‚           text: JSON.stringify(result, null, 2),
â”‚         }],
â”‚       };
â”‚     } catch (error) {
â”‚       return {
â”‚         content: [{
â”‚           type: 'text',
â”‚           text: `Error: ${error.message}`,
â”‚         }],
â”‚         isError: true,
â”‚       };
â”‚     }
â”‚   });
â”‚
â”‚   // Start server
â”‚   async function main() {
â”‚     const transport = new StdioServerTransport();
â”‚     await server.connect(transport);
â”‚     console.error('ETL Toolkit MCP Server running');
â”‚   }
â”‚
â”‚   main().catch(console.error);
â”‚
â””â”€â”€ bridge.py                                       # NEW (80 lines)
    #!/usr/bin/env python3
    """
    Python Bridge for ETL MCP Server

    Receives commands from Node.js and executes Python ETL logic.
    """

    import sys
    import json
    import os
    from dotenv import load_dotenv

    # Load environment variables
    load_dotenv()

    # P0: Import only VideoTranscriber
    # P1: Will import WebCollector, EmailSampler, BookProcessor
    from collectors.video_transcriber import VideoTranscriber

    def main():
        if len(sys.argv) < 3:
            print(json.dumps({"error": "Usage: bridge.py <operation> <params_json>"}))
            sys.exit(1)

        operation = sys.argv[1]
        params = json.loads(sys.argv[2])

        try:
            # P0: Only transcribe_video implemented
            if operation == 'transcribe_video':
                collector = VideoTranscriber()
                result = collector.collect(**params)

            # P1: Will add other operations
            # elif operation == 'collect_web_content':
            #     collector = WebCollector()
            #     result = collector.collect(**params)

            else:
                result = {"error": f"Unknown operation: {operation}"}

            print(json.dumps(result))
            sys.exit(0)

        except Exception as e:
            error = {
                "error": str(e),
                "operation": operation,
                "params": params
            }
            print(json.dumps(error), file=sys.stderr)
            sys.exit(1)

    if __name__ == '__main__':
        main()
```

### Python Collectors (P0: Video Only)

```
expansion-packs/etl/lib/collectors/
â”œâ”€â”€ __init__.py                                     # NEW
â”‚   """ETL Data Collectors"""
â”‚   from .base import DataCollector
â”‚   from .video_transcriber import VideoTranscriber
â”‚
â”‚   __all__ = ['DataCollector', 'VideoTranscriber']
â”‚
â”œâ”€â”€ base.py                                         # NEW (50 lines)
â”‚   """Abstract base class for all ETL collectors."""
â”‚   from abc import ABC, abstractmethod
â”‚   from typing import Dict, Any
â”‚
â”‚   class DataCollector(ABC):
â”‚       """Base class for data collectors."""
â”‚
â”‚       @abstractmethod
â”‚       def collect(self, source: str, **kwargs) -> Dict[str, Any]:
â”‚           """
â”‚           Collect data from source.
â”‚
â”‚           Returns:
â”‚               {
â”‚                   'content': str | List[str],
â”‚                   'metadata': Dict,
â”‚                   'cost_usd': float,
â”‚                   'duration_seconds': float (optional)
â”‚               }
â”‚           """
â”‚           pass
â”‚
â”‚       @abstractmethod
â”‚       def validate(self, data: Dict) -> bool:
â”‚           """Validate collected data quality."""
â”‚           pass
â”‚
â”‚       @property
â”‚       @abstractmethod
â”‚       def metadata_schema(self) -> Dict:
â”‚           """Return metadata schema."""
â”‚           pass
â”‚
â””â”€â”€ video_transcriber.py                            # NEW (120 lines)
    """AssemblyAI video transcription collector."""
    import os
    import assemblyai as aai
    from typing import Dict, Any
    from .base import DataCollector

    class VideoTranscriber(DataCollector):
        """Transcribe video/audio using AssemblyAI."""

        def __init__(self):
            api_key = os.getenv('ASSEMBLYAI_API_KEY')
            if not api_key:
                raise ValueError(
                    "ASSEMBLYAI_API_KEY not set. "
                    "Add to .env file: ASSEMBLYAI_API_KEY=your-key"
                )
            aai.settings.api_key = api_key

        def collect(self, source_url: str, language: str = 'en',
                   speaker_labels: bool = True) -> Dict[str, Any]:
            """
            Transcribe video/audio.

            Args:
                source_url: URL to video/audio file
                language: Language code (default: 'en')
                speaker_labels: Enable speaker detection

            Returns:
                {
                    'transcript': str,
                    'confidence': float,
                    'speakers': List[Dict],
                    'timestamps': List[Dict],
                    'duration_seconds': float,
                    'cost_usd': float,
                    'metadata': Dict
                }
            """
            # Configure transcription
            transcriber = aai.Transcriber()
            config = aai.TranscriptionConfig(
                language_code=language,
                speaker_labels=speaker_labels
            )

            # Transcribe (blocking call)
            print(f"Transcribing {source_url}...", file=sys.stderr)
            transcript = transcriber.transcribe(source_url, config=config)

            # Wait for completion
            if transcript.status == aai.TranscriptStatus.error:
                raise RuntimeError(f"Transcription failed: {transcript.error}")

            # Calculate cost
            duration_hours = transcript.audio_duration / 3600
            cost_usd = duration_hours * 0.67  # $0.67/hour

            # Build result
            result = {
                'transcript': transcript.text,
                'confidence': transcript.confidence,
                'speakers': [
                    {
                        'speaker': u.speaker,
                        'text': u.text,
                        'start': u.start,
                        'end': u.end
                    }
                    for u in (transcript.utterances or [])
                ],
                'timestamps': [
                    {
                        'start': w.start,
                        'end': w.end,
                        'text': w.text,
                        'confidence': w.confidence
                    }
                    for w in transcript.words
                ],
                'duration_seconds': transcript.audio_duration,
                'cost_usd': round(cost_usd, 4),
                'metadata': {
                    'language': language,
                    'audio_duration': transcript.audio_duration,
                    'word_count': len(transcript.words),
                    'speaker_count': len(set(u.speaker for u in (transcript.utterances or [])))
                }
            }

            # Validate quality
            if not self.validate(result):
                print(
                    f"Warning: Low confidence ({result['confidence']}). "
                    f"Recommend >0.85 for production use.",
                    file=sys.stderr
                )

            return result

        def validate(self, data: Dict) -> bool:
            """Validate transcription quality (>85% confidence)."""
            return data.get('confidence', 0) > 0.85

        @property
        def metadata_schema(self) -> Dict:
            return {
                'language': 'string',
                'audio_duration': 'float',
                'word_count': 'int',
                'speaker_count': 'int'
            }
```

### P0 Tests

```
expansion-packs/etl/tests/
â”œâ”€â”€ __init__.py                                     # NEW
â”‚
â”œâ”€â”€ conftest.py                                     # NEW (40 lines)
â”‚   """Pytest fixtures for ETL tests."""
â”‚   import pytest
â”‚   import os
â”‚   from unittest.mock import Mock
â”‚
â”‚   @pytest.fixture
â”‚   def mock_assemblyai():
â”‚       """Mock AssemblyAI client."""
â”‚       mock_transcript = Mock()
â”‚       mock_transcript.status = 'completed'
â”‚       mock_transcript.text = "This is a test transcript."
â”‚       mock_transcript.confidence = 0.94
â”‚       mock_transcript.audio_duration = 60  # 1 minute
â”‚       mock_transcript.words = [
â”‚           Mock(start=0, end=100, text='This', confidence=0.95),
â”‚           Mock(start=100, end=200, text='is', confidence=0.93),
â”‚       ]
â”‚       mock_transcript.utterances = [
â”‚           Mock(speaker='A', text='This is', start=0, end=200)
â”‚       ]
â”‚       return mock_transcript
â”‚
â”‚   @pytest.fixture
â”‚   def env_with_api_key(monkeypatch):
â”‚       """Set AssemblyAI API key in environment."""
â”‚       monkeypatch.setenv('ASSEMBLYAI_API_KEY', 'test_key_12345')
â”‚
â””â”€â”€ test_p0_smoke.py                                # NEW (100 lines)
    """P0 smoke tests - verify basic functionality."""
    import pytest
    import json
    import subprocess
    from pathlib import Path

    def test_mcp_server_starts():
        """Test 1: MCP server starts without errors."""
        result = subprocess.run(
            ['node', 'lib/mcp_server.js', '--help'],
            capture_output=True,
            timeout=5,
            cwd=Path(__file__).parent.parent
        )
        # Server should at least start (may exit with code 1 for --help)
        assert result.returncode in [0, 1]

    def test_list_tools_returns_one_tool():
        """Test 2: list_tools returns transcribe_video."""
        request = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "tools/list"
        }

        result = subprocess.run(
            ['node', 'lib/mcp_server.js'],
            input=json.dumps(request),
            capture_output=True,
            text=True,
            timeout=5,
            cwd=Path(__file__).parent.parent
        )

        # Parse MCP response
        response = json.loads(result.stdout)
        assert 'tools' in response
        assert len(response['tools']) == 1
        assert response['tools'][0]['name'] == 'transcribe_video'

    def test_transcribe_video_executes(mock_assemblyai, env_with_api_key):
        """Test 3: transcribe_video tool executes (mock)."""
        # This test requires mocking AssemblyAI at Python level
        # For P0, we verify the bridge can be called
        from lib.bridge import main as bridge_main

        # Would test actual execution with mocked AssemblyAI
        # For P0, verify VideoTranscriber imports correctly
        from lib.collectors.video_transcriber import VideoTranscriber
        assert VideoTranscriber is not None

    def test_cost_tracking_works():
        """Test 4: Cost calculation is accurate."""
        from lib.collectors.video_transcriber import VideoTranscriber

        # Calculate cost for 1 hour
        duration_hours = 1.0
        expected_cost = duration_hours * 0.67

        # Cost should be $0.67 for 1 hour
        assert expected_cost == 0.67

        # Cost for 30 minutes
        duration_hours = 0.5
        expected_cost = duration_hours * 0.67
        assert expected_cost == 0.335

    def test_error_handling():
        """Test 5: Error handling works."""
        from lib.collectors.video_transcriber import VideoTranscriber

        # Missing API key should raise ValueError
        import os
        old_key = os.environ.get('ASSEMBLYAI_API_KEY')
        if 'ASSEMBLYAI_API_KEY' in os.environ:
            del os.environ['ASSEMBLYAI_API_KEY']

        with pytest.raises(ValueError, match="ASSEMBLYAI_API_KEY"):
            VideoTranscriber()

        # Restore key
        if old_key:
            os.environ['ASSEMBLYAI_API_KEY'] = old_key
```

### P0 Documentation

```
expansion-packs/etl/docs/
â”œâ”€â”€ API-KEY-SETUP.md                                # NEW
â”‚   # AssemblyAI API Key Setup
â”‚
â”‚   ## Get API Key
â”‚
â”‚   1. Sign up at https://www.assemblyai.com/
â”‚   2. Navigate to Dashboard â†’ API Keys
â”‚   3. Copy your API key
â”‚
â”‚   ## Configure
â”‚
â”‚   ```bash
â”‚   cd expansion-packs/etl
â”‚   cp .env.example .env
â”‚   ```
â”‚
â”‚   Edit `.env`:
â”‚   ```
â”‚   ASSEMBLYAI_API_KEY=your-actual-key-here
â”‚   ```
â”‚
â”‚   ## Verify
â”‚
â”‚   ```bash
â”‚   python -c "import os; from dotenv import load_dotenv; load_dotenv(); print('API Key:', os.getenv('ASSEMBLYAI_API_KEY')[:10] + '...')"
â”‚   ```
â”‚
â”‚   Should output: `API Key: your-actual...`
â”‚
â””â”€â”€ P0-COMPLETION-CHECKLIST.md                      # NEW
    # P0 Completion Checklist

    Use this checklist to verify P0 is complete before moving to P1.

    ## Infrastructure
    - [ ] Node.js 18+ installed
    - [ ] Python 3.11+ installed
    - [ ] 1MCP installed and running
    - [ ] AssemblyAI API key configured

    ## Functionality
    - [ ] MCP server starts without errors
    - [ ] `list_tools` returns `transcribe_video`
    - [ ] Python bridge accepts JSON correctly
    - [ ] VideoTranscriber class instantiates
    - [ ] Real transcription works (1-minute test)

    ## Testing
    - [ ] Smoke tests pass (5/5)
    - [ ] Manual test: transcribe test video
    - [ ] Cost tracking accurate (Â±5%)
    - [ ] Error handling catches invalid URLs

    ## Integration
    - [ ] Registered in 1MCP successfully
    - [ ] `1mcp mcp list` shows etl-toolkit
    - [ ] MMOS can call transcribe_video
    - [ ] Result JSON valid and complete

    ## Documentation
    - [ ] README updated
    - [ ] API key setup documented
    - [ ] Example usage added

    ## Proof of Concept
    - [ ] End-to-end test successful:
          "Claude Code â†’ 1MCP â†’ ETL â†’ AssemblyAI â†’ Result"
    - [ ] Demo to stakeholders completed
    - [ ] P0 sign-off obtained

    âœ… **P0 COMPLETE** when all checkboxes marked
```

### P0 Summary

**Files Created:** 15
**Lines of Code:** ~700 (Node.js: ~150, Python: ~250, Tests: ~140, Config: ~160)
**Time Investment:** 11 hours
**Deliverable:** Video transcription working via 1MCP

---

## Story 2: Remaining Collectors (Week 2 - 6h)

**Goal:** Web, Email, Book collectors production-ready
**Success:** 3 collectors with unit tests, quality validation

### New Collectors

```
expansion-packs/etl/lib/collectors/
â”œâ”€â”€ web_collector.py                                # NEW (150 lines)
â”‚   [Complete BeautifulSoup + html2text implementation]
â”‚   [See Architecture doc for full code]
â”‚
â”œâ”€â”€ email_sampler.py                                # NEW (130 lines)
â”‚   [Complete mailbox + query sampling implementation]
â”‚   [See Architecture doc for full code]
â”‚
â””â”€â”€ book_processor.py                               # NEW (140 lines)
    [Complete PyPDF2 + EPUB + chunking implementation]
    [See Architecture doc for full code]
```

### New Transformers

```
expansion-packs/etl/lib/transformers/
â”œâ”€â”€ __init__.py                                     # NEW
â”‚
â”œâ”€â”€ chunker.py                                      # NEW (60 lines)
â”‚   [Token-based chunking with tiktoken]
â”‚   [See Architecture doc]
â”‚
â”œâ”€â”€ markdown_converter.py                           # NEW (40 lines)
â”‚   [html2text wrapper]
â”‚
â”œâ”€â”€ privacy_filter.py                               # NEW (70 lines)
â”‚   [PII removal implementation]
â”‚
â””â”€â”€ formatter.py                                    # NEW (50 lines)
    [Output formatting utilities]
```

### Story 2 Tests

```
expansion-packs/etl/tests/unit/
â”œâ”€â”€ test_web_collector.py                           # NEW (80 lines)
â”œâ”€â”€ test_email_sampler.py                           # NEW (90 lines)
â”œâ”€â”€ test_book_processor.py                          # NEW (85 lines)
â”œâ”€â”€ test_chunker.py                                 # NEW (60 lines)
â”œâ”€â”€ test_privacy_filter.py                          # NEW (70 lines)
â””â”€â”€ test_markdown_converter.py                      # NEW (50 lines)
```

**Files Created:** 10
**Time Investment:** 6 hours

---

## Story 3: MCP + Presets (Week 2 - 4h)

**Goal:** All 4 tools registered, presets configured
**Success:** Tools callable, presets load correct tools

### MCP Server Updates

```
expansion-packs/etl/lib/
â”œâ”€â”€ mcp_server.js                                   # UPDATE (+100 lines)
â”‚   [Add 3 more tool definitions to list_tools]
â”‚   [Update call_tool routing]
â”‚
â””â”€â”€ bridge.py                                       # UPDATE (+30 lines)
    [Add routing for 3 new operations]
```

### 1MCP Configuration

```
expansion-packs/etl/
â”œâ”€â”€ .1mcp-registration.sh                           # NEW (30 lines)
â”‚   #!/bin/bash
â”‚   # ETL Toolkit - 1MCP Registration Script
â”‚
â”‚   set -e
â”‚
â”‚   echo "Registering ETL Toolkit in 1MCP..."
â”‚
â”‚   # Register MCP
â”‚   ETL_PATH="$(cd "$(dirname "$0")" && pwd)"
â”‚   1mcp mcp add etl-toolkit -- node "$ETL_PATH/lib/mcp_server.js"
â”‚
â”‚   echo "Updating presets..."
â”‚
â”‚   # Update existing presets
â”‚   1mcp preset update aios-dev --filter "github,browser,etl-toolkit"
â”‚   1mcp preset update aios-research --filter "context7,browser,etl-toolkit"
â”‚
â”‚   # Create MMOS preset
â”‚   1mcp preset create aios-mmos --filter "context7,etl-toolkit"
â”‚
â”‚   echo "âœ… ETL Toolkit registered successfully"
â”‚   echo ""
â”‚   echo "Verify with:"
â”‚   echo "  1mcp mcp list | grep etl-toolkit"
â”‚   echo "  1mcp preset list"
â”‚
â””â”€â”€ config/
    â””â”€â”€ presets.yaml                                # NEW (60 lines)
        # ETL Toolkit - 1MCP Preset Configuration

        presets:
          aios-dev:
            filter: [github, browser, etl-toolkit]
            tokens: ~45K
            increment: +10K (ETL)
            agents: [@dev, @qa, @sm, @po]
            etl_use_cases:
              - Web scraping for competitor analysis in PRs
              - Documentation extraction from URLs
              - GitHub README content collection

          aios-research:
            filter: [context7, browser, etl-toolkit]
            tokens: ~60K
            increment: +10K (ETL)
            agents: [@architect, @analyst]
            etl_use_cases:
              - Deep web research with scraping
              - Video tutorial transcription
              - Technical documentation extraction
              - Book/PDF processing for research

          aios-mmos:
            filter: [context7, etl-toolkit]
            tokens: ~55K
            increment: +10K (ETL)
            agents: [MMOS workflows]
            etl_use_cases:
              - Video interview transcription (primary)
              - Email archive sampling for decisions
              - Book/PDF processing for expertise
              - Web content collection for context

        token_budgets:
          direct_etl: +50K tokens (âŒ NOT recommended)
          via_1mcp: +10K tokens (âœ… Recommended)
          savings: 80% reduction
```

### Story 3 Tests

```
expansion-packs/etl/tests/integration/
â””â”€â”€ test_1mcp_integration.py                        # NEW (100 lines)
    [Test preset loading, tool availability, token budgets]
```

**Files Created:** 4
**Time Investment:** 4 hours

---

## Story 4: Tests + Docs + CI/CD (Week 2 - 12h)

**Goal:** Production-grade quality & documentation
**Success:** 85%+ coverage, docs complete, CI operational

### Complete Test Suite

```
expansion-packs/etl/tests/
â”œâ”€â”€ unit/ (completed in Story 2, see above)
â”‚
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_mcp_server.py                          # NEW (120 lines)
â”‚   â”œâ”€â”€ test_1mcp_integration.py (from Story 3)
â”‚   â””â”€â”€ test_python_bridge.py                       # NEW (80 lines)
â”‚
â”œâ”€â”€ e2e/
â”‚   â””â”€â”€ test_agent_workflows.py                     # NEW (150 lines)
â”‚       def test_analyst_web_scraping():
â”‚       def test_docs_video_transcription():
â”‚       def test_mmos_full_pipeline():
â”‚
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample_1min_video.mp4                       # NEW
    â”œâ”€â”€ sample_webpage.html                         # NEW
    â”œâ”€â”€ sample_emails.mbox                          # NEW
    â””â”€â”€ sample_book.pdf                             # NEW
```

### Complete Documentation

```
expansion-packs/etl/
â”œâ”€â”€ README.md                                       # UPDATE (complete guide)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ QUICKSTART.md                               # NEW (300 lines)
â”‚   â”‚   # ETL Toolkit - 5-Minute Quick Start
â”‚   â”‚   [Installation, API key setup, first transcription]
â”‚   â”‚
â”‚   â”œâ”€â”€ API.md                                      # NEW (500 lines)
â”‚   â”‚   # ETL Toolkit - API Reference
â”‚   â”‚   [Complete tool documentation with schemas]
â”‚   â”‚
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md                          # NEW (400 lines)
â”‚   â”‚   # ETL Toolkit - Troubleshooting Guide
â”‚   â”‚   [Common issues, solutions, diagnostics]
â”‚   â”‚
â”‚   â”œâ”€â”€ INTEGRATION.md                              # NEW (350 lines)
â”‚   â”‚   # Agent Integration Guide
â”‚   â”‚   [How to use ETL in AIOS agents]
â”‚   â”‚
â”‚   â””â”€â”€ ARCHITECTURE.md                             # NEW (800 lines)
â”‚       # Technical Architecture
â”‚       [See full architecture doc created earlier]
â”‚
â”œâ”€â”€ checklists/
â”‚   â”œâ”€â”€ collection-quality.md                       # NEW (200 lines)
â”‚   â”œâ”€â”€ security-validation.md                      # NEW (150 lines)
â”‚   â””â”€â”€ completeness-check.md                       # NEW (120 lines)
â”‚
â””â”€â”€ templates/
    â”œâ”€â”€ collection-log.md                           # NEW
    â”œâ”€â”€ transcript-metadata.json                    # NEW
    â””â”€â”€ collection-summary.yaml                     # NEW
```

### CI/CD Pipeline

```
expansion-packs/etl/.github/
â””â”€â”€ workflows/
    â”œâ”€â”€ etl-ci.yml                                  # NEW (100 lines)
    â”‚   name: ETL Tests
    â”‚   on: [push, pull_request]
    â”‚   jobs:
    â”‚     test:
    â”‚       - Setup Python 3.11 + Node 18
    â”‚       - Install dependencies
    â”‚       - Run linting (eslint, flake8)
    â”‚       - Run tests (pytest, jest)
    â”‚       - Upload coverage
    â”‚       - Validate MCP server starts
    â”‚
    â””â”€â”€ etl-release.yml                             # NEW (80 lines)
        name: Release
        on:
          push:
            tags:
              - 'v*'
        jobs:
          release:
            - Build package
            - Run full test suite
            - Create GitHub release
            - Notify team
```

**Files Created:** 25+
**Time Investment:** 12 hours

---

## Story 5: Batch + Cache (Week 3 - 7h)

**Goal:** High-ROI performance features
**Success:** Batch 50+ sources, 40% cost reduction

### Batch Processing

```
expansion-packs/etl/lib/
â”œâ”€â”€ batch_processor.py                              # NEW (200 lines)
â”‚   """Parallel batch collection."""
â”‚   import asyncio
â”‚   from typing import List, Dict
â”‚   from tqdm import tqdm
â”‚
â”‚   class BatchCollector:
â”‚       async def collect_all(self, sources: List[Dict]):
â”‚           """Collect multiple sources in parallel."""
â”‚           tasks = []
â”‚           for source in sources:
â”‚               if source['type'] == 'web':
â”‚                   task = self.web_collector.collect(source['url'])
â”‚               elif source['type'] == 'video':
â”‚                   task = self.video_transcriber.collect(source['url'])
â”‚               tasks.append(task)
â”‚
â”‚           results = await asyncio.gather(*tasks, return_exceptions=True)
â”‚           return self._handle_results(results)
â”‚
â””â”€â”€ cache.py                                        # NEW (150 lines)
    """Smart caching layer."""
    import os
    import json
    import time
    from pathlib import Path

    class CacheManager:
        def cache_web_scrape(self, url, content, ttl=86400):
            """Cache web scrape (24h TTL)."""

        def cache_transcript(self, video_url, data, ttl=None):
            """Cache transcript (permanent)."""

        def cache_email_sample(self, query, emails, ttl=604800):
            """Cache email sample (1 week)."""

        def get_cached(self, key):
            """Retrieve cached data."""

        def invalidate(self, key):
            """Invalidate cache entry."""

        def clean_expired(self):
            """Remove expired entries."""
```

### Monitoring

```
expansion-packs/etl/lib/monitoring/
â”œâ”€â”€ __init__.py                                     # NEW
â”œâ”€â”€ metrics.py                                      # NEW (120 lines)
â”œâ”€â”€ logger.py                                       # NEW (80 lines)
â””â”€â”€ cost_tracker.py                                 # NEW (100 lines)
```

### Configuration

```
expansion-packs/etl/config/
â””â”€â”€ cache-config.yaml                               # NEW
    backend: filesystem
    cache_dir: .cache/etl
    max_size_mb: 1000
    ttl_defaults:
      web: 86400
      video: null
      email: 604800
```

### Story 5 Tests

```
expansion-packs/etl/tests/unit/
â”œâ”€â”€ test_batch_processor.py                         # NEW (100 lines)
â””â”€â”€ test_cache.py                                   # NEW (90 lines)

expansion-packs/etl/tests/integration/
â””â”€â”€ test_batch_with_cache.py                        # NEW (80 lines)
```

**Files Created:** 10
**Time Investment:** 7 hours

---

## Complete File Tree (All Stories)

```
expansion-packs/etl/
â”œâ”€â”€ package.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example
â”œâ”€â”€ README.md
â”œâ”€â”€ .1mcp-registration.sh
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ mcp_server.js (Node.js MCP server)
â”‚   â”œâ”€â”€ bridge.py (Python bridge)
â”‚   â”‚
â”‚   â”œâ”€â”€ collectors/ (Python collectors)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ video_transcriber.py (P0)
â”‚   â”‚   â”œâ”€â”€ web_collector.py (P1)
â”‚   â”‚   â”œâ”€â”€ email_sampler.py (P1)
â”‚   â”‚   â””â”€â”€ book_processor.py (P1)
â”‚   â”‚
â”‚   â”œâ”€â”€ transformers/ (Data transformers)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â”œâ”€â”€ formatter.py
â”‚   â”‚   â”œâ”€â”€ markdown_converter.py
â”‚   â”‚   â””â”€â”€ privacy_filter.py
â”‚   â”‚
â”‚   â”œâ”€â”€ batch_processor.py (P2)
â”‚   â”œâ”€â”€ cache.py (P2)
â”‚   â”‚
â”‚   â””â”€â”€ monitoring/ (P2)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ cost_tracker.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ presets.yaml
â”‚   â””â”€â”€ cache-config.yaml
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_p0_smoke.py
â”‚   â”‚
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_web_collector.py
â”‚   â”‚   â”œâ”€â”€ test_video_transcriber.py
â”‚   â”‚   â”œâ”€â”€ test_email_sampler.py
â”‚   â”‚   â”œâ”€â”€ test_book_processor.py
â”‚   â”‚   â”œâ”€â”€ test_chunker.py
â”‚   â”‚   â”œâ”€â”€ test_privacy_filter.py
â”‚   â”‚   â”œâ”€â”€ test_markdown_converter.py
â”‚   â”‚   â”œâ”€â”€ test_batch_processor.py
â”‚   â”‚   â””â”€â”€ test_cache.py
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_mcp_server.py
â”‚   â”‚   â”œâ”€â”€ test_1mcp_integration.py
â”‚   â”‚   â””â”€â”€ test_python_bridge.py
â”‚   â”‚
â”‚   â”œâ”€â”€ e2e/
â”‚   â”‚   â””â”€â”€ test_agent_workflows.py
â”‚   â”‚
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ sample_1min_video.mp4
â”‚       â”œâ”€â”€ sample_webpage.html
â”‚       â”œâ”€â”€ sample_emails.mbox
â”‚       â””â”€â”€ sample_book.pdf
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ QUICKSTART.md
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md
â”‚   â”œâ”€â”€ INTEGRATION.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ API-KEY-SETUP.md
â”‚   â””â”€â”€ P0-COMPLETION-CHECKLIST.md
â”‚
â”œâ”€â”€ checklists/
â”‚   â”œâ”€â”€ collection-quality.md
â”‚   â”œâ”€â”€ security-validation.md
â”‚   â””â”€â”€ completeness-check.md
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ collection-log.md
â”‚   â”œâ”€â”€ transcript-metadata.json
â”‚   â””â”€â”€ collection-summary.yaml
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â”œâ”€â”€ etl-ci.yml
        â””â”€â”€ etl-release.yml
```

---

## File Count Summary

| Category | P0 | P1 | P2 | Total |
|----------|----|----|----|----|
| **Configuration** | 5 | 2 | 1 | 8 |
| **Core Code** | 4 | 8 | 5 | 17 |
| **Tests** | 2 | 9 | 3 | 14 |
| **Documentation** | 3 | 10 | 0 | 13 |
| **CI/CD** | 0 | 2 | 0 | 2 |
| **Fixtures** | 1 | 3 | 0 | 4 |
| **Monitoring** | 0 | 0 | 4 | 4 |
| **Templates** | 0 | 3 | 0 | 3 |
| **Scripts** | 0 | 1 | 0 | 1 |
| **TOTAL** | **15** | **38** | **13** | **66** |

---

## Lines of Code Summary

| Category | Lines | Files |
|----------|-------|-------|
| **Node.js (MCP Server)** | ~250 | 1 |
| **Python (Collectors)** | ~800 | 8 |
| **Python (Transformers)** | ~270 | 4 |
| **Python (Monitoring)** | ~300 | 3 |
| **Python (Tests)** | ~1,200 | 14 |
| **Documentation** | ~2,700 | 13 |
| **Configuration** | ~300 | 8 |
| **CI/CD** | ~180 | 2 |
| **TOTAL** | **~6,000 lines** | **53 files** |

---

## Development Order (Recommended)

### Week 1: Foundation
```
Day 1: package.json, requirements.txt, .gitignore, .env.example, README.md
Day 1-2: lib/mcp_server.js, lib/bridge.py
Day 2: lib/collectors/base.py
Day 3-4: lib/collectors/video_transcriber.py
Day 4: tests/conftest.py, tests/test_p0_smoke.py
Day 5: docs/API-KEY-SETUP.md, docs/P0-COMPLETION-CHECKLIST.md
Day 5: .1mcp-registration.sh (basic version)
```

### Week 2: Production
```
Day 6: lib/collectors/web_collector.py + lib/transformers/markdown_converter.py
Day 7: lib/collectors/email_sampler.py + lib/transformers/privacy_filter.py
Day 7: lib/collectors/book_processor.py + lib/transformers/chunker.py
Day 8: Update lib/mcp_server.js, lib/bridge.py
Day 9: config/presets.yaml, update .1mcp-registration.sh
Day 10: tests/integration/, tests/e2e/
Day 11-12: All docs/, checklists/, templates/, .github/workflows/
```

### Week 3: Optimization
```
Day 11-12: lib/batch_processor.py
Day 13: lib/cache.py, config/cache-config.yaml
Day 14: lib/monitoring/
Day 14: Update docs, final tests
Day 15: Release preparation
```

---

## Usage in Story Creation

When creating AIOS stories, reference this document:

**Example Story Template:**
```markdown
# Story X.X: ETL [Component Name]

## Files to Create
[List from this document]

## Files to Update
[List from this document]

## Acceptance Criteria
- [ ] All files created
- [ ] Tests passing
- [ ] Documentation updated
```

---

**Version:** 1.0
**Status:** âœ… Complete Reference
**Usage:** Story creation, development tracking, completeness verification
**Next Action:** Use as source for creating individual story files
